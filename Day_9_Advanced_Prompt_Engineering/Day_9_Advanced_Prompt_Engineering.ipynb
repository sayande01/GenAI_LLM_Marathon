{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnSCULSdTlYE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Prompt Engineering with Google Gemini API\n",
        "\n",
        "**Project Name:** Advanced Prompt Engineering  \n",
        "**Date:** February 12th, Day 10\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Introduction and Objective\n",
        "\n",
        "**Introduction:**  \n",
        "Prompt engineering is the art of designing inputs (prompts) for large language models (LLMs) to guide them toward producing desired outputs. While basic prompting works for simple tasks, advanced prompt engineering techniques can significantly enhance performance on complex tasks without the need for fine-tuning. Techniques such as few-shot prompting, chain-of-thought (CoT) prompting, and prompt chaining allow us to guide LLMs more precisely, improve reasoning, and structure multi-turn tasks.\n",
        "\n",
        "**Objective:**  \n",
        "- Understand the key advanced techniques in prompt engineering.\n",
        "- Learn how to use few-shot prompting to provide examples and improve output quality.\n",
        "- Explore chain-of-thought prompting to encourage step-by-step reasoning.\n",
        "- Discover prompt chaining and template design for multi-turn or complex workflows.\n",
        "- Recognize the limitations of prompt engineering and when additional methods (like fine-tuning) might be needed.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Metadata\n",
        "\n",
        "- **Framework/API:** Google Gemini API (via `google.generativeai`)\n",
        "- **Models Used:** Gemini (Gemini Pro or similar, depending on your account and availability)\n",
        "- **Technologies:** Python, Google Gemini API, standard Python libraries for demonstration\n",
        "- **Environment:** Jupyter Notebook / Google Colab (CPU/GPU, depending on your configuration)\n",
        "- **Applications:** Advanced text generation, multi-step reasoning tasks, chatbots, and content creation\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Conceptual Overview\n",
        "\n",
        "### 3.1 What Is Advanced Prompt Engineering?\n",
        "\n",
        "Advanced prompt engineering involves creating prompts that do more than just ask a question. It includes:\n",
        "- **Few-Shot Prompting:** Providing a few examples to the model in the prompt so that it learns the desired style or pattern.\n",
        "- **Chain-of-Thought (CoT) Prompting:** Encouraging the model to think step-by-step or explain its reasoning before giving a final answer.\n",
        "- **Prompt Chaining:** Breaking a complex task into a series of smaller, sequential prompts that build on one another.\n",
        "- **Templates:** Designing reusable prompt templates to standardize interactions.\n",
        "\n",
        "### 3.2 Why Is It Important?\n",
        "\n",
        "- **Maximized Performance:**  \n",
        "  Advanced prompts can extract higher-quality, more coherent, and contextually accurate outputs from LLMs.\n",
        "- **Resource Savings:**  \n",
        "  They allow you to leverage powerful LLMs without resorting to computationally expensive fine-tuning.\n",
        "- **Flexibility:**  \n",
        "  They can be adapted on the fly to different tasks, domains, or styles.\n",
        "\n",
        "### 3.3 Mathematical and Logical Intuition\n",
        "\n",
        "When you provide a few examples (few-shot) or instruct the model to think step-by-step (chain-of-thought), you are effectively biasing the model's probability distributions toward a particular structure. For instance:\n",
        "- **Few-Shot Prompting:**  \n",
        "  The model learns from the examples, adjusting its conditional probability:\n",
        "  \\[\n",
        "  P(\\text{output} \\mid \\text{prompt with examples})\n",
        "  \\]\n",
        "- **Chain-of-Thought Prompting:**  \n",
        "  The prompt encourages intermediate reasoning steps, which can be seen as an unrolling of a series of latent reasoning steps before producing the final output.\n",
        "\n",
        "### 3.4 Advantages and Disadvantages\n",
        "\n",
        "**Advantages:**\n",
        "- **Improved Accuracy:**  \n",
        "  Provides context and examples, reducing ambiguity in model responses.\n",
        "- **No Model Retraining:**  \n",
        "  Enhances output quality without additional model fine-tuning.\n",
        "- **Versatility:**  \n",
        "  Applicable to various tasks like summarization, question answering, creative writing, etc.\n",
        "\n",
        "**Disadvantages:**\n",
        "- **Prompt Sensitivity:**  \n",
        "  Small changes in the prompt can lead to significant output variations.\n",
        "- **Limited by Model Capabilities:**  \n",
        "  Even advanced prompts may fail if the task exceeds the model's inherent knowledge.\n",
        "- **Iterative Process:**  \n",
        "  Requires experimentation and refinement to get optimal results.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Implementation Using Google Gemini API\n",
        "\n",
        "Below, we demonstrate advanced prompt engineering using the Google Gemini API. (Make sure you have access to Gemini and have your API key ready.)\n",
        "\n",
        "### 4.1 Setup: Connecting to the Gemini API\n",
        "üî• Ultimate Guide to Advanced Prompt Engineering with Google Gemini API\n",
        "üìå Table of Contents\n",
        "1Ô∏è‚É£ Introduction\n",
        "2Ô∏è‚É£ Metadata & Setup\n",
        "3Ô∏è‚É£ Core Prompting Techniques\n",
        "\n",
        "    ‚úÖ Zero-Shot Prompting\n",
        "    ‚úÖ Few-Shot Prompting\n",
        "    ‚úÖ Chain-of-Thought (CoT) Prompting\n",
        "    ‚úÖ Self-Consistency Prompting\n",
        "    ‚úÖ Prompt Chaining\n",
        "    ‚úÖ Instruction-Based Prompting\n",
        "    ‚úÖ Role Prompting\n",
        "    ‚úÖ Persona-Based Prompting\n",
        "    ‚úÖ Multi-Turn Conversational Prompting\n",
        "    ‚úÖ Deliberate Misinformation Handling\n",
        "    ‚úÖ Ethical & Bias-Control Prompting\n",
        "4Ô∏è‚É£ Best Practices & Optimization\n",
        "5Ô∏è‚É£ Conclusion\n",
        "\n"
      ],
      "metadata": {
        "id": "zKsuFdi_Trsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# Authenticate using your Gemini API key\n",
        "GEMINI_API_KEY = \"AIzaSyBe-n-OoAb2paq2D-xGqbAy1zl2NyVg_8o\"  # Replace with your actual API key\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# Initialize the model (here we use Gemini Pro as an example)\n",
        "model = genai.GenerativeModel(\"gemini-pro\")\n",
        "\n",
        "# Define a helper function to get a response from Gemini\n",
        "def get_gemini_response(prompt):\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text.strip()\n",
        "\n",
        "# Test the API connection with a simple prompt\n",
        "test_prompt = \"What is the capital of France?\"\n",
        "print(\"Test Response:\", get_gemini_response(test_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Hi1EiUw9TuOg",
        "outputId": "b7c0204c-28c0-4603-c064-3f135aca6834"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Response: Paris\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation for Cell 1:**  \n",
        "- We import the `google.generativeai` module to use the Gemini API.\n",
        "- The API is configured with your API key.\n",
        "- We initialize a generative model (e.g., Gemini Pro).\n",
        "- A helper function `get_gemini_response` is defined to wrap the API call for generating responses.\n",
        "- A simple test prompt (\"What is the capital of France?\") verifies that the API connection is working, which should return \"Paris\" or similar.\n"
      ],
      "metadata": {
        "id": "4CQfkEmuVNo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "basic_prompt = \"What is the capital of India?\"\n",
        "basic_response = get_gemini_response(basic_prompt)\n",
        "print(\"Basic Prompt Response:\", basic_response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "iEg7okjdUOI4",
        "outputId": "5852daa6-a70e-45fd-b94b-0611fc823d0f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Basic Prompt Response: New Delhi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation for Cell 2:**  \n",
        "- A basic prompt is issued without any extra context or examples.\n",
        "- The response is generated by Gemini.\n",
        "- This example demonstrates a simple query that retrieves a straightforward answer.\n"
      ],
      "metadata": {
        "id": "tm2Nq1v_VZ7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_prompt = \"\"\"\n",
        "Determine the sentiment of the following sentences. Label each as Positive, Negative, or Neutral.\n",
        "\n",
        "1. \"I absolutely loved the movie!\" ‚Üí Positive\n",
        "2. \"The food was awful and the service was terrible.\" ‚Üí Negative\n",
        "3. \"The event was okay, not too great but not bad either.\" ‚Üí Neutral\n",
        "\n",
        "Now, determine the sentiment of this sentence:\n",
        "\"I enjoyed the lively atmosphere and the delicious pasta.\"\n",
        "\"\"\"\n",
        "\n",
        "few_shot_response = get_gemini_response(few_shot_prompt)\n",
        "print(\"Few-Shot Prompt Response:\", few_shot_response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "D8IMlcZTVTEl",
        "outputId": "31a6f378-ceff-4a2b-fbed-af29cac76cf1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Few-Shot Prompt Response: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation for Cell 3:**  \n",
        "- This cell uses a few-shot prompt where the prompt includes examples of sentiment analysis.\n",
        "- The model is given three examples and then asked to determine the sentiment of a new sentence.\n",
        "- The response demonstrates that the model can infer the expected pattern from the examples.\n"
      ],
      "metadata": {
        "id": "JEZbAtF7WEAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cot_prompt = \"\"\"\n",
        "Solve the problem step-by-step:\n",
        "\"Lisa had 4 apples. She bought 7 more apples. Then, she gave 3 apples to her friend.\n",
        "How many apples does Lisa have now?\"\n",
        "\n",
        "Step 1: Write down the initial number of apples.\n",
        "Step 2: Add the apples she bought.\n",
        "Step 3: Subtract the apples given away.\n",
        "Final Answer:\n",
        "\"\"\"\n",
        "\n",
        "cot_response = get_gemini_response(cot_prompt)\n",
        "print(\"Chain-of-Thought Response:\", cot_response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "el-fVsqMVfAB",
        "outputId": "12535892-9e9c-49a6-b712-06df7d418959"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chain-of-Thought Response: **Step 1: Write down the initial number of apples.**\n",
            "Lisa had 4 apples.\n",
            "\n",
            "**Step 2: Add the apples she bought.**\n",
            "She bought 7 more apples.\n",
            "\n",
            "4 + 7 = 11\n",
            "\n",
            "**Step 3: Subtract the apples given away.**\n",
            "She gave 3 apples to her friend.\n",
            "\n",
            "11 - 3 = 8\n",
            "\n",
            "**Final Answer:**\n",
            "Lisa has 8 apples now.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation for Cell 4:**  \n",
        "- The chain-of-thought (CoT) prompt instructs the model to reason through a problem step-by-step.\n",
        "- The prompt breaks the problem into distinct steps before asking for the final answer.\n",
        "- This technique helps the model provide a clear, logical explanation of its reasoning process.\n"
      ],
      "metadata": {
        "id": "LaXKt4wXWNmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prompt Chaining**"
      ],
      "metadata": {
        "id": "W4p27M-rWUV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Identify the issue in a customer complaint\n",
        "step1_prompt = \"A customer says: 'My internet connection is extremely slow.' What is the most likely issue?\"\n",
        "step1_response = get_gemini_response(step1_prompt)\n",
        "\n",
        "# Step 2: Suggest a troubleshooting step based on the identified issue\n",
        "step2_prompt = f\"Based on the issue '{step1_response}', suggest a practical troubleshooting step.\"\n",
        "step2_response = get_gemini_response(step2_prompt)\n",
        "\n",
        "print(\"Prompt Chaining:\")\n",
        "print(\"Step 1 - Identified Issue:\", step1_response)\n",
        "print(\"Step 2 - Suggested Fix:\", step2_response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "u3_NoCWEWGwQ",
        "outputId": "9723fa52-274f-4df0-f02d-e9a311ebd4e4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt Chaining:\n",
            "Step 1 - Identified Issue: Slow or inadequate bandwidth\n",
            "Step 2 - Suggested Fix: **Practical Troubleshooting Step:**\n",
            "\n",
            "**Verify Network Bottlenecks:**\n",
            "\n",
            "* **Test bandwidth:** Use online speed test tools or built-in network diagnostic utilities to measure the actual bandwidth and latency.\n",
            "* **Check network devices:** Ensure that all network devices (e.g., routers, switches, modems) are functioning properly. Update firmware if necessary.\n",
            "* **Identify traffic bottlenecks:** Monitor network traffic to identify any applications or devices hogging bandwidth. Use network monitoring tools to pinpoint the source of congestion.\n",
            "* **Inspect cables and connections:** Examine all network cables (e.g., Ethernet, fiber) for damage or loose connections. Replace any faulty cables or tighten connections.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GsBJvPmDWnSh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation for Cell 5:**  \n",
        "- **Prompt Chaining** splits a complex task into sequential steps.\n",
        "- In this example, the first prompt identifies the issue in a customer complaint.\n",
        "- The second prompt uses the result from the first step to suggest a troubleshooting step.\n",
        "- This chaining of prompts helps in building a multi-step conversation where each response informs the next.\n"
      ],
      "metadata": {
        "id": "gZ8PJIReWnyB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üöÄ 3. Core Prompting Techniques\n",
        "\n",
        "üéØ 3.1 Zero-Shot Prompting (Basic Prompting)\n",
        "\n",
        "üîπ No examples are provided‚ÄîLLM figures out the task itself.\n",
        "\n",
        "üîπ Works well for general knowledge queries but lacks structure.\n",
        "\n",
        "üìå Example:\n"
      ],
      "metadata": {
        "id": "tIY_z8kfXgPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero_shot_prompt = \"Who won the FIFA World Cup in 2018?\"\n",
        "response = get_gemini_response(zero_shot_prompt)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "YTrkvHr1WYys",
        "outputId": "1444f6f5-9c71-43c9-da9d-904106ee6c9c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "France\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ 3.2 Few-Shot Prompting\n",
        "\n",
        "üîπ Provides a few labeled examples to guide the LLM.\n",
        "\n",
        "üîπ Works great for classification, sentiment analysis, etc.\n",
        "\n",
        "üìå Example:\n"
      ],
      "metadata": {
        "id": "aqwrCJu8XqVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_prompt = \"\"\"\n",
        "Classify the sentiment of these sentences:\n",
        "\n",
        "1. \"I love this product, it's amazing!\" ‚Üí Positive\n",
        "2. \"The service was terrible, I'm never coming back.\" ‚Üí Negative\n",
        "3. \"The event was okay, not too great but not bad either.\" ‚Üí Neutral\n",
        "\n",
        "Now, classify this sentence:\n",
        "\"I really enjoyed the friendly staff and quick service.\"\n",
        "\"\"\"\n",
        "\n",
        "response = get_gemini_response(few_shot_prompt)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "F42JVeVpXmSn",
        "outputId": "8a7a144f-4f98-42c8-ea12-7d483c0dd55f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ 3.3 Chain-of-Thought (CoT) Prompting\n",
        "\n",
        "üîπ Encourages step-by-step reasoning to improve accuracy.\n",
        "\n",
        "üîπ Best for math, logic puzzles, or complex decision-making tasks.\n",
        "\n",
        "üìå Example:\n"
      ],
      "metadata": {
        "id": "XbOsLITHXxdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cot_prompt = \"\"\"\n",
        "Solve step-by-step:\n",
        "\n",
        "Lisa has 10 chocolates. She gives 3 to her friend and buys 5 more.\n",
        "How many chocolates does she have now?\n",
        "\n",
        "Step 1: Start with 10 chocolates.\n",
        "Step 2: Subtract 3 chocolates given away\n",
        "Step 3: Add 5 chocolates bought\n",
        "Final Answer:\n",
        "\"\"\"\n",
        "\n",
        "response = get_gemini_response(cot_prompt)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "gS44nZpEXuM4",
        "outputId": "a00d729d-86ad-465c-f912-dc50a0f0107e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Step 1: Start with 10 chocolates.**\n",
            "Lisa has 10 chocolates.\n",
            "\n",
            "**Step 2: Subtract 3 chocolates given away**\n",
            "Lisa gives 3 chocolates to her friend.\n",
            "10 chocolates - 3 chocolates = 7 chocolates\n",
            "\n",
            "**Step 3: Add 5 chocolates bought**\n",
            "Lisa buys 5 more chocolates.\n",
            "7 chocolates + 5 chocolates = 12 chocolates\n",
            "\n",
            "**Final Answer:**\n",
            "Lisa has 12 chocolates now.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FgMN5tDPX23M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ 3.4 Self-Consistency Prompting\n",
        "\n",
        "üîπ Runs multiple Chain-of-Thought (CoT) processes and selects the most common answer.\n",
        "\n",
        "üîπ Reduces LLM errors by ensuring consistency in reasoning.\n"
      ],
      "metadata": {
        "id": "7Ray528SYDNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cot_runs = [get_gemini_response(cot_prompt) for _ in range(5)]\n",
        "final_answer = max(set(cot_runs), key=cot_runs.count)\n",
        "print(final_answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "U9pU5zfRYEmS",
        "outputId": "2b265600-765e-4f7d-96c3-3ec6ef7b885d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Step 1: Start with 10 chocolates.**  \n",
            "10 chocolates  \n",
            "\n",
            "**Step 2: Subtract 3 chocolates given away**  \n",
            "10 chocolates - 3 chocolates = 7 chocolates  \n",
            "\n",
            "**Step 3: Add 5 chocolates bought**  \n",
            "7 chocolates + 5 chocolates = 12 chocolates  \n",
            "\n",
            "**Final Answer:**  \n",
            "Lisa has 12 chocolates now.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ 3.5 Prompt Chaining\n",
        "\n",
        "üîπ Splits a complex task into sequential prompts, each building on the previous step.\n"
      ],
      "metadata": {
        "id": "0zD9EQXQYLSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "step1_prompt = \"Summarize this text: 'The internet is a global network that connects millions of computers...'\"\n",
        "step1_response = get_gemini_response(step1_prompt)\n",
        "\n",
        "step2_prompt = f\"Convert this summary into bullet points: {step1_response}\"\n",
        "step2_response = get_gemini_response(step2_prompt)\n",
        "\n",
        "print(\"Step 1 - Summary:\", step1_response)\n",
        "print(\"Step 2 - Bullet Points:\", step2_response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "EPsfIN9aYHJi",
        "outputId": "d6d8ce09-b914-4c7e-a0b4-d3eb227432ca"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1 - Summary: The internet is a vast, interconnected network of computers that spans the globe.\n",
            "Step 2 - Bullet Points: - The internet is a vast network of computers.\n",
            "- This network is interconnected, meaning that computers can communicate with each other.\n",
            "- The internet spans the globe, meaning that it can be accessed from anywhere in the world.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ 3.6 Instruction-Based Prompting\n",
        "\n",
        "üîπ Gives explicit step-by-step instructions.\n",
        "\n",
        "üîπ Ideal for structured outputs like JSON, CSV, or code snippets.\n",
        "\n",
        "üìå Example:\n"
      ],
      "metadata": {
        "id": "gLXXjdQkYQ2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instruction_prompt = \"\"\"\n",
        "Generate a JSON response for a customer order:\n",
        "Customer: John Doe\n",
        "Items: Laptop, Mouse, Keyboard\n",
        "Total: $1500\n",
        "\n",
        "Format:\n",
        "{\n",
        "  \"customer\": \"John Doe\",\n",
        "  \"items\": [\"Laptop\", \"Mouse\", \"Keyboard\"],\n",
        "  \"total\": \"$1500\"\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "response = get_gemini_response(instruction_prompt)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "LgmahIvNYOPa",
        "outputId": "fe2cc148-297b-42e3-d3df-4964f1f54703"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"customer\": \"John Doe\",\n",
            "  \"items\": [\"Laptop\", \"Mouse\", \"Keyboard\"],\n",
            "  \"total\": \"$1500\"\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ 3.7 Role Prompting\n",
        "\n",
        "üîπ Assigns a role to the model (e.g., \"You are a doctor...\").\n",
        "\n",
        "üîπ Helps in domain-specific expertise.\n"
      ],
      "metadata": {
        "id": "pIdw_oO7YfON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "role_prompt = \"\"\"\n",
        "You are a medical expert. Explain the symptoms of diabetes in simple terms for a 12-year-old.\n",
        "\"\"\"\n",
        "\n",
        "response = get_gemini_response(role_prompt)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "ekp4FjlqYT4f",
        "outputId": "61ad8e95-c825-45e5-f51b-d98997e810a9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagine your body is like a car that needs fuel to run. In the case of your body, the fuel is called glucose, which comes from the food you eat. To use this fuel, your body needs a key called insulin. Diabetes is a condition where your body doesn't have enough insulin or doesn't use insulin as well as it should. This makes it hard for your body to use the glucose, and it starts to build up in your blood.\n",
            "\n",
            "**Here are some signs that you may have diabetes:**\n",
            "\n",
            "* **Feeling thirsty a lot:** When there's too much glucose in your blood, your body tries to get rid of it by making you pee often. This can make you feel thirsty all the time.\n",
            "* **Going to the bathroom a lot:** As your body tries to get rid of the extra glucose, you'll probably notice that you need to go to the bathroom to pee more often than usual.\n",
            "* **Feeling tired or weak:** Without enough insulin to use glucose for energy, your body can feel weak or tired.\n",
            "* **Losing weight without trying:** If your body can't use glucose for energy, it starts to break down fat and muscle, which can lead to weight loss.\n",
            "* **Blurry vision:** High blood glucose can cause the lenses in your eyes to swell, making vision blurry.\n",
            "* **Slow-healing sores:** Without enough insulin, your body can't heal wounds as well as it should.\n",
            "\n",
            "If you have any of these symptoms, it's important to talk to your parents or a doctor so they can check your blood glucose levels. Early diagnosis and treatment of diabetes can help you stay healthy and prevent serious problems in the future.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ 3.8 Persona-Based Prompting\n",
        "\n",
        "üîπ Makes the LLM respond with a personality or specific style.\n",
        "\n",
        "üìå Example:\n"
      ],
      "metadata": {
        "id": "UJK1B4k9Y9OF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "persona_prompt = \"\"\"\n",
        "You are Arthur Conan Doyel. Describe a Detecives first apperance in the scene :\n",
        "\"\"\"\n",
        "\n",
        "response = get_gemini_response(persona_prompt)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "adX0Cff9Yhtd",
        "outputId": "1b14c937-703f-4413-cee4-183f5b0f362d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the dimly lit chamber, the air hung heavy with anticipation. Inspector Lestrade paced restlessly, his florid face etched with concern. Suddenly, the door creaked open, and a figure stepped in.\n",
            "\n",
            "His keen eyes surveyed the room, sharp as flints. A tall, lean man, with a hawk-like nose and a goatee that seemed to bristle with intelligence. Dressed in a worn tweed suit and a deerstalker hat, a pipe jutting from between his teeth, he radiated an aura of quiet confidence.\n",
            "\n",
            "\"Excuse me,\" he said, his voice a mixture of brusqueness and politeness. \"I believe I am expected. Sherlock Holmes, at your service.\"\n",
            "\n",
            "Lestrade's eyes widened in surprise. \"Holmes? But... you're not who I asked for.\"\n",
            "\n",
            "\"Indeed,\" Holmes replied. \"But I have a reputation for assisting the Met in their most perplexing cases.\"\n",
            "\n",
            "He scanned the scene, his gaze falling upon the body lying on the floor. A faint smile played upon his lips as he knelt down to examine it.\n",
            "\n",
            "\"My dear Lestrade,\" he drawled, \"I believe we have a rather intricate puzzle on our hands.\"\n",
            "\n",
            "With the cold precision of a surgeon, Holmes began his investigation, scrutinizing every detail, every piece of evidence. The others in the room watched in silence, their hopes pinned on this mysterious stranger who had arrived on their doorstep like a breath of fresh air in a stagnant pool.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ 3.9 Multi-Turn Conversational Prompting\n",
        "\n",
        "üîπ Maintains context across multiple responses.\n"
      ],
      "metadata": {
        "id": "uEtJ2kHuZqOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_history = []\n",
        "\n",
        "def chat_with_gemini(user_input):\n",
        "    conversation_history.append(f\"User: {user_input}\")\n",
        "    full_prompt = \"\\n\".join(conversation_history)\n",
        "    response = get_gemini_response(full_prompt)\n",
        "    conversation_history.append(f\"AI: {response}\")\n",
        "    return response\n",
        "\n",
        "print(chat_with_gemini(\"Hello, who won the 2018 World Cup?\"))\n",
        "print(chat_with_gemini(\"What was the final score?\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "lywjg_26Y_ex",
        "outputId": "6cc7cef5-fb9f-481f-976e-ef4f4a211f65"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "France\n",
            "AI: 4-2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ 3.10 Ethical & Bias-Control Prompting\n",
        "\n",
        "üîπ Ensures unbiased and neutral responses.\n",
        "\n",
        "üìå Example:\n"
      ],
      "metadata": {
        "id": "1zbHsbLKZx5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bias_prompt = \"\"\"\n",
        "Explain the impact of social media on mental health. Ensure your response remains unbiased and includes both positive and negative aspects.\n",
        "\"\"\"\n",
        "\n",
        "response = get_gemini_response(bias_prompt)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "vHlY6d7KZs8Z",
        "outputId": "ede4ee7d-ec60-45da-a78c-86957afdd2d9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Positive Impacts:**\n",
            "\n",
            "* **Social connectedness:** Social media platforms offer opportunities for individuals to connect with friends, family, and like-minded individuals, potentially reducing feelings of isolation and loneliness.\n",
            "* **Information access:** Users can access a wealth of mental health information, resources, and support groups online, facilitating self-education and empowering individuals to take control of their well-being.\n",
            "* **Support and Validation:** Online communities can provide a space for individuals to share experiences, offer support, and receive validation from peers who may understand their challenges.\n",
            "* **Increased awareness:** Social media campaigns and public discussions can raise awareness about mental health issues, reducing stigma and encouraging individuals to seek help.\n",
            "* **Mobile access:** Smartphone accessibility makes mental health resources and support readily available anytime, anywhere.\n",
            "\n",
            "**Negative Impacts:**\n",
            "\n",
            "* **Cyberbullying and online harassment:** Social media provides a platform for anonymity, which can lead to harmful comments and cyberbullying, damaging self-esteem and mental well-being.\n",
            "* **Social comparison and unrealistic expectations:** The curated and often idealized content on social media can foster feelings of inadequacy and social anxiety.\n",
            "* **Addiction and excessive use:** Spending excessive time on social media can lead to addiction, disrupting sleep patterns, academic performance, and relationships.\n",
            "* **FOMO (Fear of Missing Out):** The constant stream of updates and notifications may create a sense of pressure to engage constantly, potentially leading to anxiety and stress.\n",
            "* **Privacy concerns:** Sharing personal information on social media can compromise privacy and increase the risk of identity theft or harassment.\n",
            "\n",
            "**Moderation and Responsible Use:**\n",
            "\n",
            "To mitigate potential negative impacts, it is crucial to use social media in moderation and with intention. Individuals should be mindful of the content they consume, engage in positive interactions, and seek professional help when necessary. Parents and educators play a significant role in guiding young people towards responsible social media use.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Limitations of Prompt Engineering:\n",
        "- **Sensitivity:** Small changes in prompt wording can lead to different responses.\n",
        "- **Complexity:** For very complex tasks, even advanced prompts may not yield perfect results.\n",
        "- **Hallucination:** LLMs may sometimes generate plausible-sounding but incorrect information.\n",
        "\n",
        "#### Best Practices:\n",
        "- **Be Specific:** Provide clear, detailed instructions.\n",
        "- **Use Examples:** Include few-shot examples to guide the model.\n",
        "- **Encourage Reasoning:** Use chain-of-thought prompts to improve logic and accuracy.\n",
        "- **Iterate:** Test and refine your prompts to achieve the best results.\n",
        "- **Combine Techniques:** Use prompt chaining for multi-step tasks.\n"
      ],
      "metadata": {
        "id": "kPEO7c0oZ__q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DAoMbUILZ1PS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}