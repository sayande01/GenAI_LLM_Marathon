{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Dive into Transformer Architecture\n",
        "\n",
        "**Main Topic:** Transformer Architecture – Self-Attention, Encoder-Decoder Structure, and Positional Encoding  \n",
        "**Dataset:** IMDB Movie Reviews (for sentiment classification)  \n",
        "**Framework:** TensorFlow (Keras API)  \n",
        "**Author:** Your Name  \n",
        "**Date:** YYYY-MM-DD\n",
        "\n",
        "---\n",
        "\n",
        "## Objective\n",
        "\n",
        "- **Conceptual Understanding:**  \n",
        "  - **Self-Attention Mechanism:** Learn how queries, keys, and values are computed and combined using attention weights.\n",
        "  - **Encoder-Decoder Structure:** Understand how the encoder processes the input and how the decoder (if used) generates output. In this notebook, we focus on the encoder side for classification.\n",
        "  - **Positional Encoding:** Understand the need for, and mathematical formulation of, positional encodings to incorporate sequence order into embeddings.\n",
        "\n",
        "- **Practical Implementation:**  \n",
        "  Implement a Transformer block in TensorFlow and integrate it into a sentiment classification model using the IMDB dataset.\n",
        "\n",
        "- **Performance Analysis:**  \n",
        "  Evaluate and discuss model performance and design choices.\n",
        "\n",
        "---\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [Introduction](#Introduction)\n",
        "2. [Theoretical Background](#Theoretical-Background)\n",
        "   - Self-Attention Mechanism\n",
        "   - Encoder-Decoder Structure\n",
        "   - Positional Encoding\n",
        "3. [Implementation in TensorFlow](#Implementation)\n",
        "   - Positional Encoding Layer\n",
        "   - Transformer Block\n",
        "4. [Application: IMDB Sentiment Classification](#Application)\n",
        "5. [Performance Evaluation](#Evaluation)\n",
        "6. [Conclusion and Key Takeaways](#Conclusion)\n"
      ],
      "metadata": {
        "id": "5rfWEYsgN_Za"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Introduction\n",
        "\n",
        "Transformers have revolutionized natural language processing by eliminating recurrence and convolution through the self-attention mechanism. They capture relationships between tokens irrespective of their positions in the sequence. This notebook provides an in-depth look at key components of the Transformer architecture:\n",
        "- **Self-Attention:** How every token in a sequence can interact with every other token.\n",
        "- **Encoder-Decoder Structure:** The core structure used in sequence-to-sequence tasks (with a focus on the encoder for classification).\n",
        "- **Positional Encoding:** How position information is injected into the model.\n",
        "\n",
        "We will implement a simplified Transformer block using TensorFlow and apply it to the IMDB sentiment classification task.\n"
      ],
      "metadata": {
        "id": "HTsXdJr8ODyE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Theoretical Background\n",
        "\n",
        "### 2.1 Self-Attention Mechanism\n",
        "\n",
        "Self-attention allows each position in a sequence to attend to all other positions. For an input sequence represented as a matrix \\(X \\in \\mathbb{R}^{n \\times d}\\) (where \\(n\\) is the sequence length and \\(d\\) is the dimensionality), we compute three matrices:\n",
        "- **Query (\\(Q\\))**\n",
        "- **Key (\\(K\\))**\n",
        "- **Value (\\(V\\))**\n",
        "\n",
        "These are obtained via learned linear transformations:\n",
        "\\[\n",
        "Q = XW^Q,\\quad K = XW^K,\\quad V = XW^V\n",
        "\\]\n",
        "The attention scores are computed as:\n",
        "\\[\n",
        "\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^\\top}{\\sqrt{d_k}}\\right)V\n",
        "\\]\n",
        "where \\(d_k\\) is the dimension of the queries/keys.\n",
        "\n",
        "### 2.2 Encoder-Decoder Structure\n",
        "\n",
        "- **Encoder:** Processes the input sequence and generates a representation that captures contextual information.\n",
        "- **Decoder:** Uses the encoder’s output along with previous target tokens (shifted right) to generate the output sequence.\n",
        "  \n",
        "In this notebook, we focus on the **encoder side** to extract features for classification. The complete encoder-decoder setup is crucial in tasks like machine translation.\n",
        "\n",
        "### 2.3 Positional Encoding\n",
        "\n",
        "Since transformers process all tokens in parallel, we add positional encodings to the input embeddings to retain information about the position of tokens. A common formula for positional encoding is:\n",
        "\\[\n",
        "PE_{(pos,2i)} = \\sin\\left(\\frac{pos}{10000^{\\frac{2i}{d}}}\\right),\\quad\n",
        "PE_{(pos,2i+1)} = \\cos\\left(\\frac{pos}{10000^{\\frac{2i}{d}}}\\right)\n",
        "\\]\n",
        "where \\(pos\\) is the token position and \\(i\\) is the dimension index. These encodings are added to the input embeddings to provide positional context.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Implementation in TensorFlow\n",
        "\n",
        "In this section, we build a custom Transformer block in TensorFlow, including the self-attention and feed-forward network components, along with a positional encoding layer.\n",
        "\n",
        "### 3.1 Importing Libraries\n"
      ],
      "metadata": {
        "id": "hhrJZshfOFXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkAvyVMiOAh3",
        "outputId": "96959424-eb1d-4ae5-d116-dd672e275e0a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interpretation:\n",
        "This cell imports TensorFlow along with necessary modules such as Keras layers and models. We also import NumPy, Matplotlib, and Seaborn for numerical operations and visualizations. We print the TensorFlow version to ensure compatibility.\n"
      ],
      "metadata": {
        "id": "TxioE9YlOJzC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Positional Encoding Layer\n",
        "\n",
        "The following cell defines a custom layer for positional encoding.\n"
      ],
      "metadata": {
        "id": "lQZuX4RrOQUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Positional Encoding Layer\n",
        "\n",
        "class PositionalEncoding(layers.Layer):\n",
        "    def __init__(self, sequence_len, d_model):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.pos_encoding = self.positional_encoding(sequence_len, d_model)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(PositionalEncoding, self).get_config()\n",
        "        config.update({\n",
        "            \"pos_encoding\": self.pos_encoding,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def positional_encoding(self, position, d_model):\n",
        "        angle_rads = self.get_angles(np.arange(position)[:, np.newaxis],\n",
        "                                     np.arange(d_model)[np.newaxis, :],\n",
        "                                     d_model)\n",
        "        # apply sin to even indices; cos to odd indices\n",
        "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "        pos_encoding = angle_rads[np.newaxis, ...]\n",
        "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "    def get_angles(self, pos, i, d_model):\n",
        "        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "        return pos * angle_rates\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
        "\n",
        "# Test the positional encoding layer\n",
        "sample_pos_encoding = PositionalEncoding(sequence_len=50, d_model=512)\n",
        "dummy_inputs = tf.zeros((1, 50, 512))\n",
        "encoded = sample_pos_encoding(dummy_inputs)\n",
        "print(\"Positional encoding shape:\", encoded.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6BUvrEvOHFN",
        "outputId": "19763ebf-a153-454b-a8a8-7f1585a88ce4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positional encoding shape: (1, 50, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Detailed Explanation:\n",
        "- **`class PositionalEncoding(layers.Layer):`**  \n",
        "  We define a custom Keras layer for positional encoding by subclassing `layers.Layer`.\n",
        "\n",
        "- **`def __init__(self, sequence_len, d_model):`**  \n",
        "  The constructor takes:\n",
        "  - `sequence_len`: The maximum length of input sequences.\n",
        "  - `d_model`: The embedding dimension.\n",
        "  \n",
        "- **`self.pos_encoding = self.positional_encoding(sequence_len, d_model)`**  \n",
        "  Computes the positional encodings immediately during initialization and stores them.\n",
        "\n",
        "- **`def positional_encoding(self, position, d_model):`**  \n",
        "  This method calculates the positional encodings:\n",
        "  - **`angle_rads = self.get_angles(...):`**  \n",
        "    Computes a matrix of angles for each position and dimension.\n",
        "  - **`angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])` and `angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])`:**  \n",
        "    Applies sine to even indices and cosine to odd indices.\n",
        "  - **`pos_encoding = angle_rads[np.newaxis, ...]`:**  \n",
        "    Adds a new axis to match the batch dimension.\n",
        "  - **`tf.cast(pos_encoding, dtype=tf.float32)`:**  \n",
        "    Casts the encoding to TensorFlow’s float32 type.\n",
        "\n",
        "- **`def get_angles(self, pos, i, d_model):`**  \n",
        "  This helper function calculates the angle rates used in the sinusoidal functions:\n",
        "  - **`angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))`:**  \n",
        "    Computes the scaling factor for each dimension.\n",
        "  - **`return pos * angle_rates`:**  \n",
        "    Multiplies the position indices by the angle rates to obtain the final angles.\n",
        "\n",
        "- **`def call(self, inputs):`**  \n",
        "  This method is called when the layer is applied. It adds the precomputed positional encoding to the input tensor, aligning with the input’s sequence length.\n",
        "\n",
        "- **Testing the layer:**  \n",
        "  We create a `PositionalEncoding` instance with a sequence length of 50 and embedding dimension of 512, then pass a dummy tensor of zeros to verify the output shape.\n",
        "  \n",
        "- **`print(\"Positional encoding shape:\", encoded.shape)`**  \n",
        "  Ensures that the output has the expected shape: `(batch_size, sequence_length, d_model)`.\n"
      ],
      "metadata": {
        "id": "yLJ_4CNEOW2p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Multi-Head Self-Attention and Transformer Block\n",
        "\n",
        "Next, we implement a simplified Transformer block that includes multi-head self-attention and a feed-forward network.\n"
      ],
      "metadata": {
        "id": "vdvkxc_BOYYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Define a Basic Transformer Block\n",
        "\n",
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = models.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training, mask=None):\n",
        "        # Self-Attention block\n",
        "        attn_output = self.att(inputs, inputs, inputs, attention_mask=mask)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        # Feed-Forward Network block\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "# Test the Transformer block\n",
        "sample_transformer = TransformerBlock(embed_dim=64, num_heads=4, ff_dim=128)\n",
        "dummy_data = tf.random.uniform((1, 10, 64))  # batch_size=1, sequence_length=10, embed_dim=64\n",
        "output_data = sample_transformer(dummy_data, training=False)\n",
        "print(\"Transformer block output shape:\", output_data.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfxHa95aOTRj",
        "outputId": "21020a8b-d451-474e-a752-5fa4b4dd70ed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer block output shape: (1, 10, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Detailed Explanation:\n",
        "- **`class TransformerBlock(layers.Layer):`**  \n",
        "  We define a custom Transformer block as a subclass of `layers.Layer`.\n",
        "\n",
        "- **`def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):`**  \n",
        "  The constructor takes:\n",
        "  - `embed_dim`: The dimension of the embeddings.\n",
        "  - `num_heads`: The number of attention heads for multi-head attention.\n",
        "  - `ff_dim`: The hidden dimension of the feed-forward network.\n",
        "  - `rate`: Dropout rate for regularization.\n",
        "  \n",
        "- **`self.att = layers.MultiHeadAttention(...)`:**  \n",
        "  Instantiates the multi-head self-attention layer. This layer computes attention scores for each token with respect to all other tokens.\n",
        "  \n",
        "- **`self.ffn = models.Sequential([...])`:**  \n",
        "  Defines a simple feed-forward network (FFN) consisting of:\n",
        "  - A Dense layer with ReLU activation and `ff_dim` units.\n",
        "  - A Dense layer with `embed_dim` units to project back to the original embedding size.\n",
        "  \n",
        "- **`self.layernorm1` and `self.layernorm2`:**  \n",
        "  Two layer normalization layers that help stabilize and speed up training by normalizing the inputs of each sub-layer.\n",
        "  \n",
        "- **`self.dropout1` and `self.dropout2`:**  \n",
        "  Two dropout layers that randomly zero out some elements during training to prevent overfitting.\n",
        "  \n",
        "- **`def call(self, inputs, training, mask=None):`**  \n",
        "  The `call` method defines how the layer processes inputs:\n",
        "  - **Self-Attention:**  \n",
        "    `attn_output = self.att(inputs, inputs, inputs, attention_mask=mask)`  \n",
        "    Here, the same input tensor is used as query, key, and value.\n",
        "  \n",
        "  - **Dropout and Residual Connection:**  \n",
        "    The attention output is passed through dropout and then added to the original input (residual connection), followed by layer normalization.\n",
        "  \n",
        "  - **Feed-Forward Network:**  \n",
        "    The normalized output `out1` is processed through the FFN, followed by another dropout and residual addition with `out1`, then normalized again.\n",
        "  \n",
        "- **Testing the Block:**  \n",
        "  We create a `TransformerBlock` instance with a small embedding dimension (64) and 4 attention heads. We generate dummy data with shape `(1, 10, 64)` (batch size 1, sequence length 10) and pass it through the block. Finally, we print the output shape to confirm that it remains `(1, 10, 64)`.\n"
      ],
      "metadata": {
        "id": "8zm0RSPtOb78"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Application: IMDB Sentiment Classification\n",
        "\n",
        "We will now use the IMDB movie review dataset to demonstrate the Transformer block as a feature extractor in a text classification model.\n"
      ],
      "metadata": {
        "id": "pkq7GEMNOeW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loading and Preprocessing\n",
        "\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "# Set parameters for the IMDB dataset\n",
        "max_features = 5000  # Vocabulary size\n",
        "maxlen = 200         # Maximum length of reviews\n",
        "embedding_dim = 64   # Embedding dimension\n",
        "\n",
        "# Load the dataset\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Pad sequences to the same length\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "print(\"Training data shape:\", x_train.shape)\n",
        "print(\"Test data shape:\", x_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uL1V4MohOdRH",
        "outputId": "b8c7a236-adea-4f77-effc-1c22fc55bfba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Training data shape: (25000, 200)\n",
            "Test data shape: (25000, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Detailed Explanation:\n",
        "- **`from tensorflow.keras.datasets import imdb` and `from tensorflow.keras.preprocessing import sequence`:**  \n",
        "  Import the IMDB dataset and helper function for padding sequences.\n",
        "  \n",
        "- **`max_features = 5000`:**  \n",
        "  Limit the vocabulary to the 5000 most common words.\n",
        "  \n",
        "- **`maxlen = 200`:**  \n",
        "  Set the maximum review length to 200 tokens. Reviews shorter than this are padded, and longer reviews are truncated.\n",
        "  \n",
        "- **`embedding_dim = 64`:**  \n",
        "  Define the dimension of the word embeddings to be 64.\n",
        "  \n",
        "- **`imdb.load_data(num_words=max_features)`:**  \n",
        "  Loads the IMDB dataset, ensuring only the top 5000 words are considered.\n",
        "  \n",
        "- **`sequence.pad_sequences(...)`:**  \n",
        "  Pads all reviews to ensure they are exactly 200 tokens long. This uniformity is required for batch processing in neural networks.\n",
        "  \n",
        "- **`print(\"Training data shape:\", x_train.shape)` and similar for test data:**  \n",
        "  Prints the shapes of the training and testing datasets to confirm that the data is loaded and preprocessed correctly. Typically, the shape will be `(num_samples, maxlen)`.\n"
      ],
      "metadata": {
        "id": "47qJrgPdOjye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Building the Classification Model\n",
        "\n",
        "We now build a model that uses an embedding layer, the positional encoding layer, our custom Transformer block, and a classification head.\n"
      ],
      "metadata": {
        "id": "MwX5RnByOlPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the Transformer-based Classification Model\n",
        "\n",
        "from tensorflow.keras import Input, Model\n",
        "\n",
        "def create_model(max_features, maxlen, embedding_dim):\n",
        "    inputs = Input(shape=(maxlen,))\n",
        "    # Embedding layer converts token IDs to embeddings\n",
        "    x = layers.Embedding(input_dim=max_features, output_dim=embedding_dim)(inputs)\n",
        "    # Add positional encoding to embeddings\n",
        "    x = PositionalEncoding(sequence_len=maxlen, d_model=embedding_dim)(x)\n",
        "    # Apply Transformer block\n",
        "    x = TransformerBlock(embed_dim=embedding_dim, num_heads=4, ff_dim=128)(x, training=True)\n",
        "    # Global average pooling to collapse sequence dimension\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    # Fully connected layer for classification\n",
        "    x = layers.Dense(64, activation=\"relu\")(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "model = create_model(max_features=max_features, maxlen=maxlen, embedding_dim=embedding_dim)\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "Lv7pX8Z_OgB3",
        "outputId": "8e9c1665-62c3-41f4-ac70-b1ce5e39895d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m320,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ positional_encoding_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mPositionalEncoding\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_block_1                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m83,200\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">320,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ positional_encoding_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEncoding</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_block_1                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">83,200</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m407,425\u001b[0m (1.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,425</span> (1.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m407,425\u001b[0m (1.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,425</span> (1.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Detailed Explanation:\n",
        "- **`from tensorflow.keras import Input, Model`:**  \n",
        "  Import the necessary classes to build our Keras model.\n",
        "\n",
        "- **`def create_model(max_features, maxlen, embedding_dim):`**  \n",
        "  Define a function to create our model. This function takes in parameters for vocabulary size, sequence length, and embedding dimension.\n",
        "  \n",
        "- **`inputs = Input(shape=(maxlen,))`:**  \n",
        "  Defines an input layer that expects sequences of length `maxlen`.\n",
        "  \n",
        "- **`layers.Embedding(...)`:**  \n",
        "  Converts the input word indices into dense embedding vectors of dimension `embedding_dim`. This layer maps each word index to a vector.\n",
        "  \n",
        "- **`PositionalEncoding(...)`:**  \n",
        "  Adds positional encodings to the word embeddings, ensuring that the model is aware of the token order.\n",
        "  \n",
        "- **`TransformerBlock(...)`:**  \n",
        "  Applies our custom Transformer block to the encoded embeddings. This block performs multi-head self-attention and a feed-forward operation to extract contextual features.\n",
        "  \n",
        "- **`layers.GlobalAveragePooling1D()`:**  \n",
        "  Reduces the sequence dimension by averaging across all token representations. This results in a fixed-size vector for each sample.\n",
        "  \n",
        "- **`layers.Dense(64, activation=\"relu\")`:**  \n",
        "  Adds a dense layer with 64 units and ReLU activation to further process the features.\n",
        "  \n",
        "- **`layers.Dense(1, activation=\"sigmoid\")`:**  \n",
        "  The final dense layer outputs a single probability value (using sigmoid activation) for binary classification (sentiment positive or negative).\n",
        "  \n",
        "- **Model Compilation:**  \n",
        "  The model is compiled with:\n",
        "  - **Optimizer:** Adam\n",
        "  - **Loss Function:** Binary cross-entropy (appropriate for binary classification)\n",
        "  - **Metrics:** Accuracy\n",
        "- **`model.summary()`:**  \n",
        "  Prints the model summary to show the layer configuration, output shapes, and the number of parameters.\n"
      ],
      "metadata": {
        "id": "pAYn8jSsOrzn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Training the Model\n",
        "\n",
        "We now train the model on the IMDB dataset.\n"
      ],
      "metadata": {
        "id": "GxIP7HDYOtda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Train the Model\n",
        "\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=3,                # Set to 3 for demonstration; increase for better performance.\n",
        "    batch_size=64,\n",
        "    validation_split=0.2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cJWtUyCOgEZ",
        "outputId": "f75cc5c2-ae70-4881-cf5b-9951ab0a5098"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 827ms/step - accuracy: 0.5788 - loss: 0.6498 - val_accuracy: 0.8536 - val_loss: 0.3415\n",
            "Epoch 2/3\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 788ms/step - accuracy: 0.8778 - loss: 0.2903 - val_accuracy: 0.8742 - val_loss: 0.2996\n",
            "Epoch 3/3\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 820ms/step - accuracy: 0.9191 - loss: 0.2127 - val_accuracy: 0.8704 - val_loss: 0.3184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Detailed Explanation:\n",
        "- **`model.fit(...)`:**  \n",
        "  Trains the model using the preprocessed IMDB training data (`x_train` and `y_train`).\n",
        "  \n",
        "- **Parameters Explained:**\n",
        "  - **`epochs=3`:**  \n",
        "    The number of complete passes through the training dataset. Three epochs are set here for a quick demonstration. In practice, you might use more epochs.\n",
        "  - **`batch_size=64`:**  \n",
        "    The number of samples processed before the model's weights are updated. A batch size of 64 balances training speed and stability.\n",
        "  - **`validation_split=0.2`:**  \n",
        "    Reserves 20% of the training data for validation to monitor the model’s performance on unseen data during training.\n",
        "  \n",
        "- **`history`:**  \n",
        "  The variable `history` stores training metrics (loss and accuracy for both training and validation sets) over the epochs.\n"
      ],
      "metadata": {
        "id": "mS_TH4EVOycj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Evaluating Model Performance\n"
      ],
      "metadata": {
        "id": "rukHvbdpOz2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Model\n",
        "\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuCz_2-zOgGy",
        "outputId": "1731303f-49fc-454e-e5a2-b31c778bf925"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 126ms/step - accuracy: 0.8679 - loss: 0.3161\n",
            "Test Loss: 0.3135252594947815\n",
            "Test Accuracy: 0.8703200221061707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Detailed Explanation of Cell 7:\n",
        "- **`model.evaluate(x_test, y_test)`:**  \n",
        "  Evaluates the trained model on the test dataset. This function returns the loss and the metrics (here, accuracy) computed on the test set.\n",
        "  \n",
        "- **Storing and Printing Results:**\n",
        "  - **`loss, accuracy = ...`:**  \n",
        "    Unpacks the returned loss and accuracy values into separate variables.\n",
        "  - **`print(\"Test Loss:\", loss)` and `print(\"Test Accuracy:\", accuracy)`:**  \n",
        "    Prints the test loss and test accuracy, which provide an indication of how well the model generalizes to unseen data.\n"
      ],
      "metadata": {
        "id": "rv3dbQnwO4k1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Performance Evaluation\n",
        "\n",
        "The model's performance on the IMDB sentiment classification task using a basic Transformer block is summarized by:\n",
        "- **Training and Validation Accuracy/Loss:** Observed during training.\n",
        "- **Test Accuracy:** Provides a measure of how well the model generalizes.\n",
        "\n",
        "The implementation demonstrates that even a single Transformer block, when combined with proper embedding and positional encoding, can capture contextual information effectively for classification tasks.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Conclusion and Key Takeaways\n",
        "\n",
        "- **Transformer Fundamentals:**  \n",
        "  - **Self-Attention:** Enables the model to capture relationships between tokens regardless of their distance.\n",
        "  - **Encoder-Decoder Architecture:** While we demonstrated only the encoder for classification, the full architecture is essential for tasks like translation.\n",
        "  - **Positional Encoding:** Critical for injecting sequential order into the model since transformers do not inherently capture position.\n",
        "\n",
        "- **Implementation Insights:**  \n",
        "  - We implemented a custom Transformer block in TensorFlow using Keras.\n",
        "  - The Transformer block was integrated into a sentiment classification pipeline on the IMDB dataset.\n",
        "  - Even with a basic setup, the Transformer-based model learns meaningful representations for text classification.\n",
        "\n",
        "- **Practical Relevance:**  \n",
        "  - Transformers are the backbone of modern LLMs (e.g., GPT, BERT).  \n",
        "  - Understanding their components is essential for working on advanced NLP tasks and research.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Bd-1G52NO6JW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NG_5tEEfOgJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UYkz79bmOgK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TpmuJAaFOgOS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}