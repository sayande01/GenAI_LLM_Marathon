{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Vector Databases: Storing and Retrieving Embeddings\n\n**Project Name:** Vector Databases: Storing and Retrieving Embeddings  \n**Date:** February 10th, Day 8\n\n---\n\n## 1. Introduction and Objective\n\n**Introduction:**  \nModern AI applications, especially those involving large language models (LLMs), often rely on embeddings—numerical representations of text or other data. However, as the number of embeddings grows (sometimes into the millions), it becomes crucial to have efficient methods to store, index, and retrieve these high-dimensional vectors. This is where vector databases come in. They allow for fast similarity search using metrics like cosine similarity or Euclidean distance, making them essential for applications such as semantic search, retrieval-augmented generation (RAG), and recommendation systems.\n\n**Objective:**  \n- Understand what vector databases are and why they are needed in AI applications.\n- Explore use cases such as semantic search and RAG.\n- Introduce popular vector database tools like Pinecone and Weaviate.\n- Set up a vector database (using Pinecone in our example).\n- Demonstrate storing and retrieving embeddings using a sample dataset.\n\n---\n\n## 2. Metadata\n\n- **Dataset:** (For demonstration, we will create a small set of sample texts to generate embeddings.)\n- **Technologies:** Python, Hugging Face Transformers, Pinecone (vector database service), NumPy, and Matplotlib.\n- **Tools:** Pinecone (or Weaviate can be used similarly), a pre-trained embedding model (e.g., Sentence Transformers).\n- **Environment:** Jupyter Notebook / Google Colab (CPU-friendly configuration)\n- **Applications:** Semantic search, retrieval-augmented generation (RAG), recommendation systems, and more.\n\n---\n\n## 3. Conceptual Overview\n\n### 3.1 What are Vector Databases?\n\nVector databases are specialized data stores designed to handle high-dimensional vectors (embeddings). They are optimized for performing similarity search operations rapidly by using approximate nearest neighbor (ANN) algorithms. Instead of traditional relational databases that index data by exact matching, vector databases index and retrieve data based on the closeness of vector representations.\n\n### 3.2 Use Cases\n\n- **Semantic Search:**  \n  Retrieve documents or data that are semantically similar to a given query based on vector similarity.\n- **Retrieval-Augmented Generation (RAG):**  \n  Combine language models with retrieval systems to provide relevant context for generating more accurate responses.\n- **Recommendation Systems:**  \n  Suggest items (e.g., products, movies) based on the similarity of their embeddings.\n- **Anomaly Detection:**  \n  Identify unusual data points by comparing their embeddings to those of typical data.\n\n### 3.3 Popular Tools\n\n- **Pinecone:**  \n  A managed vector database service that offers scalable and fast vector search capabilities.\n- **Weaviate:**  \n  An open-source vector search engine that also includes features like GraphQL-based querying.\n- **Milvus:**  \n  Another open-source vector database optimized for similarity search.\n\n### 3.4 Mathematical Intuition\n\nEmbeddings are points in a high-dimensional space. The similarity between two embeddings can be measured using:\n- **Cosine Similarity:**  \n  \\[\n  \\text{cosine\\_similarity}(a, b) = \\frac{a \\cdot b}{\\|a\\| \\|b\\|}\n  \\]\n- **Euclidean Distance:**  \n  \\[\n  \\text{euclidean\\_distance}(a, b) = \\sqrt{\\sum_{i=1}^{d}(a_i - b_i)^2}\n  \\]\nVector databases use these metrics to quickly retrieve the most similar vectors, even among millions of entries, by leveraging efficient indexing structures.\n\n### 3.5 Advantages and Disadvantages\n\n**Advantages:**\n- **Scalability:**  \n  Can efficiently handle millions of high-dimensional vectors.\n- **Speed:**  \n  Optimized for rapid similarity searches, crucial for real-time applications.\n- **Flexibility:**  \n  Supports a wide range of AI applications—from semantic search to recommendations.\n\n**Disadvantages:**\n- **Complexity:**  \n  Setting up and tuning a vector database may require domain-specific knowledge.\n- **Cost:**  \n  Managed services like Pinecone may incur costs as data scales.\n- **Tuning Sensitivity:**  \n  Performance may depend on hyperparameters such as the choice of similarity metric and indexing algorithm.\n\n---\n\n## 4. Implementation\n\nIn the following sections, we will demonstrate how to set up a vector database using Pinecone, store embeddings from a set of sample texts, and retrieve similar embeddings based on a query.\n","metadata":{}},{"cell_type":"code","source":"# Cell 1: Install and Import Libraries\n\n!pip install pinecone-client transformers sentence-transformers --quiet\n\nimport pinecone\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom transformers import AutoTokenizer, AutoModel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T13:07:56.157993Z","iopub.execute_input":"2025-02-10T13:07:56.158274Z","iopub.status.idle":"2025-02-10T13:08:08.788381Z","shell.execute_reply.started":"2025-02-10T13:07:56.158252Z","shell.execute_reply":"2025-02-10T13:08:08.787675Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"**Explanation for Cell 1:**  \nIn this cell, we install and import the necessary libraries:\n- **pinecone-client:** To interact with the Pinecone vector database.\n- **transformers and sentence-transformers:** To generate embeddings from text.\n- **NumPy and Matplotlib:** For numerical operations and visualizations.\n  \nThese libraries provide the tools needed for generating, storing, and retrieving embeddings.\n","metadata":{}},{"cell_type":"code","source":"pip install pinecone-client\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T13:25:21.797335Z","iopub.execute_input":"2025-02-10T13:25:21.797607Z","iopub.status.idle":"2025-02-10T13:25:26.744765Z","shell.execute_reply.started":"2025-02-10T13:25:21.797584Z","shell.execute_reply":"2025-02-10T13:25:26.743966Z"}},"outputs":[{"name":"stdout","text":"Collecting pinecone-client\n  Downloading pinecone_client-5.0.1-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2025.1.31)\nCollecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client)\n  Downloading pinecone_plugin_inference-1.1.0-py3-none-any.whl.metadata (2.2 kB)\nCollecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client)\n  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\nRequirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.12.2)\nRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.3.0)\nDownloading pinecone_client-5.0.1-py3-none-any.whl (244 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading pinecone_plugin_inference-1.1.0-py3-none-any.whl (85 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\nInstalling collected packages: pinecone-plugin-interface, pinecone-plugin-inference, pinecone-client\nSuccessfully installed pinecone-client-5.0.1 pinecone-plugin-inference-1.1.0 pinecone-plugin-interface-0.0.7\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Example vector and metadata\nvector_id = \"example-id\"\nvector_values = [0.1] * 1024  # Replace with actual embeddings\nmetadata = {\"category\": \"example-category\"}\n\n# Upsert vectors into the index\nindex.upsert(vectors=[{\"id\": vector_id, \"values\": vector_values, \"metadata\": metadata}])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T13:37:02.593216Z","iopub.execute_input":"2025-02-10T13:37:02.593500Z","iopub.status.idle":"2025-02-10T13:37:02.897071Z","shell.execute_reply.started":"2025-02-10T13:37:02.593480Z","shell.execute_reply":"2025-02-10T13:37:02.896204Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'upserted_count': 1}"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"query_vector = [0.2] * 1024  # Replace with your query embedding\ntop_k = 5  # Number of closest matches to retrieve\n\n# Query the index\n# Correct query format\nresults = index.query(\n    vector=query_vector,  # The vector to query against the index\n    top_k=top_k,          # Number of nearest neighbors to retrieve\n    include_metadata=True # Include metadata in results if desired\n)\n\n# Display results\nprint(\"Query Results:\", results)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T13:39:06.573707Z","iopub.execute_input":"2025-02-10T13:39:06.574047Z","iopub.status.idle":"2025-02-10T13:39:06.806199Z","shell.execute_reply.started":"2025-02-10T13:39:06.574019Z","shell.execute_reply":"2025-02-10T13:39:06.805204Z"}},"outputs":[{"name":"stdout","text":"Query Results: {'matches': [{'id': 'id2', 'score': 0.999999881, 'values': []},\n             {'id': 'example-id',\n              'metadata': {'category': 'example-category'},\n              'score': 0.999999881,\n              'values': []},\n             {'id': 'id1', 'score': 0.999999881, 'values': []}],\n 'namespace': '',\n 'usage': {'read_units': 6}}\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"query_vector = [0.1] * 1024  # Example query vector with 1024 dimensions\ntop_k = 5\nresults = index.query(vector=query_vector, top_k=top_k)\nprint(results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T13:39:21.326341Z","iopub.execute_input":"2025-02-10T13:39:21.326651Z","iopub.status.idle":"2025-02-10T13:39:21.356707Z","shell.execute_reply.started":"2025-02-10T13:39:21.326627Z","shell.execute_reply":"2025-02-10T13:39:21.355832Z"}},"outputs":[{"name":"stdout","text":"{'matches': [{'id': 'id2', 'score': 0.999999881, 'values': []},\n             {'id': 'example-id', 'score': 0.999999881, 'values': []},\n             {'id': 'id1', 'score': 0.999999881, 'values': []}],\n 'namespace': '',\n 'usage': {'read_units': 5}}\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from pinecone import Pinecone, ServerlessSpec\nfrom sentence_transformers import SentenceTransformer\n\n# Initialize Pinecone\napi_key = \"pcsk_3kPWqo_RDs5KaEVsr6rV6fJHbzLNczzsKJfAiTLuBaHDD5aStMdcziGwcCGong8e4nSx1Q\"\npinecone_client = Pinecone(api_key=api_key)\n\n# Define the index name\nindex_name = \"multilingual-e5-large\"\n\n# Check if the index exists\nif index_name not in pinecone_client.list_indexes().names():\n    print(f\"Index '{index_name}' not found. Please verify the index name in your Pinecone dashboard.\")\nelse:\n    print(f\"Successfully connected to index: {index_name}\")\n    index = pinecone_client.Index(index_name)\n\n# Load the Multilingual E5-Large model\nmodel = SentenceTransformer(\"intfloat/e5-large-v2\")\n\n# Example data: restaurant descriptions\nrestaurant_data = [\n    {\"id\": \"1\", \"text\": \"Italian restaurant with great pasta and wine\"},\n    {\"id\": \"2\", \"text\": \"Cozy cafe offering vegan-friendly desserts and coffee\"},\n    {\"id\": \"3\", \"text\": \"Sushi bar with fresh seafood and authentic Japanese dishes\"},\n    {\"id\": \"4\", \"text\": \"Indian restaurant with spicy curries and naan bread\"},\n    {\"id\": \"5\", \"text\": \"Mexican restaurant with tacos, burritos, and margaritas\"},\n]\n\n# Preprocess and encode data\ndef preprocess_query(query):\n    return f\"query: {query}\"\n\nvectors = [\n    {\"id\": data[\"id\"], \"values\": model.encode(preprocess_query(data[\"text\"])).tolist(), \"metadata\": {\"text\": data[\"text\"]}}\n    for data in restaurant_data\n]\n\n# Upsert data into Pinecone\nindex.upsert(vectors=vectors)\n\n# Querying the Pinecone index\nquery_text = \"I want a place with fresh sushi\"\nquery_vector = model.encode(preprocess_query(query_text)).tolist()\n\nresults = index.query(vector=query_vector, top_k=3, include_metadata=True)\nprint(f\"Query: {query_text}\\n\")\nprint(\"Top matches:\")\nfor match in results[\"matches\"]:\n    print(f\"- {match['metadata']['text']} (score: {match['score']:.4f})\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T14:04:16.761009Z","iopub.execute_input":"2025-02-10T14:04:16.761321Z","iopub.status.idle":"2025-02-10T14:04:18.704445Z","shell.execute_reply.started":"2025-02-10T14:04:16.761299Z","shell.execute_reply":"2025-02-10T14:04:18.703617Z"}},"outputs":[{"name":"stdout","text":"Successfully connected to index: multilingual-e5-large\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6919b61c1f7244b89c417a84b9613409"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9c3017bc2bb4024a462f0e12b913f3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f565590e353d44f7b8ba6051debb0a77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5733b43c7f0247e3bc1c5da6a4fe8b3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c7c746a80a74e56bed06079ad6dda0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71d1a7f7559c4602bb37cbf2eed0c144"}},"metadata":{}},{"name":"stdout","text":"Query: I want a place with fresh sushi\n\nTop matches:\n- Sushi bar with fresh seafood and authentic Japanese dishes (score: 0.8890)\n- Italian restaurant with great pasta and wine (score: 0.7939)\n- Indian restaurant with spicy curries and naan bread (score: 0.7864)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}